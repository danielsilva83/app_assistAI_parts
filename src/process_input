from flask import Flask, request, render_template,jsonify
import torch
import pandas as pd
import numpy as np
import pandas as pd
from transformers import BertTokenizer, BertModel
from tensorflow.keras.models import load_model # type: ignore

def get_bert_embeddings(texts, tokenizer, bert_model, batch_size=32):
    # Carregando o modelo e outros componentes necessários
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)
        with torch.no_grad():
            outputs = bert_model(**inputs)
        batch_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()
        embeddings.append(batch_embeddings)
        del inputs, outputs
        torch.cuda.empty_cache()
    return np.vstack(embeddings)

def preprocess_input(df, numerical_features, text_columns, tokenizer, bert_model, scaler):
    # Remover NaN em 'codigo_solicitado'
    df.fillna('', inplace=True)
    df.drop_duplicates(inplace=True)

    # Processamento dos textos com BERT
    # Aplica a função nos campos textuais em batches
    text_embeddings = []
    for column in text_columns:
        embeddings = get_bert_embeddings(df[column].tolist(), tokenizer, bert_model, batch_size=32)
        text_embeddings.append(embeddings)

    # Concatenar os embeddings textuais
    all_text_embeddings = np.hstack(text_embeddings)
    # Verificação das dimensões
    if df[numerical_features].shape[0] == all_text_embeddings.shape[0]:
        X_final = np.hstack([df[numerical_features], all_text_embeddings])
    else:
        raise ValueError("Dimensões incompatíveis entre X_normalized e text embeddings.")

    # Normalização dos dados numéricos
    X_final = scaler.transform(X_final)

    return X_final
